% ---------------------------------------------------------------------
% ---------------------------------------------------------------------
% ---------------------------------------------------------------------
\part{Conclussions and future work}
\chapter[Conclusions]{Conclusions and future work}

% ---------------------------------------------------------------------
% ---------------------------------------------------------------------
\section{Developed topics and contributions}
This thesis has covered the issues and difficulties in analyzing metabolomic data and the different techniques able to deal with those problems. A special focus has been given to the treatment and analysis of three-way and, by extension, multi-way data sets and the development and implementation of a variable selection procedure integrated at the model-fitting step.

First, a review of the properties and particularities of 'omic' data and, more specifically, of metabolomic data was performed. The main characteristics of these data are their multicollinearity, the large number of variables and their organization in complex data structures. There are a wide range of methods available for analyzing metabolomic data sets. In this thesis, many of these techniques have been presented and explained; after a review of the classical statistical methods, such as univariate tests, where their limitations have been exposed, the usefulness of PCA, PLS, ridge regression, lasso and elastic net for the analysis of metabolomic data has been assessed. After this, the thesis focused on complex data structures such as three-way or multi-way arrays and the tools for their analysis regarding compression methods such as Tucker3 and PARAFAC and also predictive modelling methods such as $N$-PLS.

A new method for combining the $N$-PLS algorithm with L1-penalization has been developed. This method is applied at the determination of the $\textbf{\text{w}}^J$ and $\textbf{\text{w}}^K$ to achieve sparse versions of the latent variables and effectively perform variable selection at the model fitting step. The penalization of both vectors, $\textbf{\text{w}}^J$ and $\textbf{\text{w}}^K$, achieves not only variable selection on the second mode ($J$), but also on the third mode ($K$). Related to the variable selection, this method allows for the construction of simpler models than standard $N$-PLS. This makes the models more interpretable and less prone to overfitting.

The new developed method sNPLS has been implemented in an R package called \texttt{sNPLS}. This package includes not only the main sNPLS algorithm but also a complete set of functions for fitting predictive models with three-way data structures, including parallelized cross-validation and repeated cross-validation procedures, processing of the data such as centering, scaling and unfolding and a wide array of plots for interpretation of the modelling results. Additionally, this is the only package for performing $N$-PLS regression models in \texttt{R}, so with its development the applicability of three-way methods to the \texttt{R} user community has been expanded.

The method and its implementation in \texttt{R} has also been validated using synthetic simulations and real data sets, showing lower prediction error than standard $N$-PLS and good performance in variable selection. The method has also been validated for the case of high multicollinearity between variables, proving that the combination of L1-penalization and $N$-PLS projection behaves similarly to elastic net, being able to select all correlated variables instead of discarding most of them and selecting only one as happens with lasso. 

Additionally, other variable selection methods such as VIP and SR have been implemented within the $N$-PLS algorithm. Then, the  variable selection performance of the three new methods was compared, obtaining similar results with sNPLS and VIP and potentially different results with SR. with any of them being superior to the other two in some cases and inferior in other cases.

\section{Future work and research lines}
\label{packagedev}
The current version of the package is the 0.4.01, which is the 59th update of the initial package. At its current state, the package is fully functional, being able of fitting sparse and standard $N$-PLS models, efficiently performing cross-validation and repeated cross-validation and providing useful plots for the interpretation of results. It also incorporates VIP and SR variable selection procedures within the $N$-PLS algorithm. The package recently incorporated generic base \texttt{R} functions for models such as \texttt{coef}, \texttt{summary} and \texttt{predict} and also has fixed all the detected bugs of the first versions of the software. According to the statistics given by \textit{CRAN}, the \texttt{sNPLS} package averages around 240 downloads per month and has accumulated more than 4500 downloads. These are similar statistics to the two other \texttt{R} packages for three-way analysis, so reception of the package seems to be great among the three-way community of \texttt{R} users.

For future versions of the package one of the priorities is including more options for the application of the penalization factor. Currently, the L1-penalty is determined by choosing the number of non-zero elements in $\textbf{\text{w}}^\text{J}$ and $\textbf{\text{w}}^\text{K}$, which can be determined by $K$-fold cross-validation or arbitrarily by the user. Ideally, the L1-penalty values should come from a continuous distribution, being able to take any value, not just discrete values as of now. Related to the application of penalty, there is ongoing work being performed on studying the possibility of adding an option for L0 penalty, This penalty can be applied using the hard-thresholding operator \parencite{zou2006adaptive}, so it should be straightforward to implement in future versions of the package.

Also the cross-validation procedure does not currently try all the possible combinations of the hyperparameter space, because when there is more than one component, all components are forced to have the same number of \texttt{keepJ} and \texttt{keepK} values. This constrain is only applied because of computational constrains, so different alternatives are being studied to be able to improve efficiency of the cross-validation procedure, thus removing the need for constraining the hyperparameter space. One of such alternatives, which will be implemented in future versions of the package will be the substitution of the grid search procedure for a random search procedure which has been demonstrated to be more efficient and also provide better estimates of uncertainty \parencite{bergstra2012random}.

Another addition regarding the tuning of the parameters and the cross-validation will be the possibility of personalizing the objective metric. Currently, the $RMSE$ is the only option for the optimization of the hyperparameter space. However, in the case of $N$-PLS-DA, other metrics related to classification methods such as missclassification rate or AUC \parencite{bradley1997use} would be more reasonable and should be implemented in future versions of the package.

Related to the optimization of the model by tuning of the hyperparameter space, alternative methods to cross-validation will be studied and implemented, such as information criteria based methods like Akaike information criterion (AIC) \parencite{akaike1974new} or Bayesian information criterion (BIC) \parencite{schwarz1978estimating}. These alternative methods should be much more efficient computationally, so they would be a great addition to the package.

It has also been already experimented with the estimation of confidence intervals for the estimates based on resampling, so this will be another addition to the package in the upcoming versions. Related to this, the possibility of estimating the uncertainty in the variable selection procedure will be estudied and implemented if feasible.

Other planned addition is the modification of the plot function so that it creates objects with all the information about the plot instead of only producing them. This way, the user will be able to fully personalize their plots and also make their plots fully reproducible without the new of repeating a large analysis.

Finally, another objective is adding more useful functions to the package for providing a comprehensive framework for three-way analyses. Functions for performing Tucker and PARAFAC models like those already implemented in the \texttt{ThreeWay} and \texttt{PTAk} packages, more pre-processing functions and an extended documentation of all of them, including some vignettes, will be introduced in future versions of the package.

The development of a new method for performing variable selection at the model-fitting step in $N$-PLS and its software implementation as an \texttt{R} package has opened a large range of research lines that should be explored in the future. These research lines can be framed in three different categories: methodological developments, software development and practical application of the method to real problems in biomedical research.

Regarding methodological developments, future research lines include:

\begin{enumerate}
    \item Study of other possible penalizations such as L0 or adaptive L1 penalization. The field of penalized regression methods is a very active research branch. Since the sNPLS method is a combination of a projection based method with a penalization method, advances in both fields could be incorporated into this technique. Adaptive L1 penalization is specially appealing for its oracle properties \parencite{zou2006adaptive}.
    \item Development of alternative methods for the selection and/or tuning of the hyperparameter space. Using $RMSE$ for the tuning of the hyperparameters results in a theoretically optimal prediction error performance at a cost of non-optimal variable selection performance. Finding an appropriate criterion for achieving optimal variable selection performance would greatly increase the flexibility and utility of the method.
    \item Derivation of standard errors and confidence intervals for sNPLS to further improve the inference capabilities of the method.
\end{enumerate}
\vspace{10pt}
In the case of software development, the proposed future research lines include:

\begin{enumerate}
    \item Improvement of the \texttt{sNPLS} \texttt{R} package as exposed in \autoref{packagedev}. This includes adding all the functionality developed by the methodological research lines, but also improving the efficiency of the computations and adding more data processing options and plots.
    \item Developing an alternative to the search grid method. Random search is one candidate, but other options should be studied such as gradient search or genetic algorithms.
    \item Study the impact of the use of different BLAS libraries on the performance of the package and implement optimizations in the algorithm based on this results.
\end{enumerate}
\vspace{10pt}
Finally, regarding practical application of the method to real biomedical problems, the potential number of research lines is immense, so a generic sample is provided:

\begin{enumerate}
    \item Application of the sNPLS method to biomarkers search in longitudinal studies.
    \item Development of prediction models for outcome in repeated measures studies.
    \item Use of the sNPLS method for the understanding of complex biological systems
\end{enumerate}
